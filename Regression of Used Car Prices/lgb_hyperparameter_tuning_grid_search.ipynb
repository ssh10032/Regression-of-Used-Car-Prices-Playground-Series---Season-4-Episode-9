{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3715b429-e0b7-4194-b1bf-4c930481c389",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd \n",
    "import polars as pl\n",
    "import os\n",
    "import optuna\n",
    "import re\n",
    "import warnings\n",
    "from sklearn.model_selection import KFold, train_test_split\n",
    "from sklearn.metrics import accuracy_score, mean_squared_error\n",
    "import lightgbm as lgb\n",
    "from lightgbm import LGBMRegressor\n",
    "from lightgbm import log_evaluation, early_stopping\n",
    "\n",
    "warnings.simplefilter('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2a232ad1-bbda-4374-9fdd-ad3650321a3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('/home/baebro/kaggle_ws/car price/data/train.csv')\n",
    "test = pd.read_csv('/home/baebro/kaggle_ws/car price/data/test.csv')\n",
    "orig = pd.read_csv('/home/baebro/kaggle_ws/car price/data/used_cars.csv')\n",
    "\n",
    "\n",
    "orig[['milage', 'price']] = orig[['milage', 'price']].apply(\n",
    "    lambda col: col.map(lambda x: int(''.join(re.findall(r'\\d+', str(x))))))\n",
    "\n",
    "train = pd.concat([train, orig], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "dda564b8-fa5e-41f2-ad8a-a9765b3743ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fill_nan_values(df):\n",
    "    \n",
    "    freq = 100\n",
    "    \n",
    "    categoricl_colums = ['brand','model','fuel_type','engine','transmission','ext_col','int_col','accident','clean_title']\n",
    "    re_ = ['model','engine','transmission','ext_col','int_col']\n",
    "    \n",
    "    for column in re_:\n",
    "        df.loc[df[column].value_counts(dropna=False)[df[column]].values < freq, column] = \"noise\"\n",
    "        \n",
    "    for column in categoricl_colums:\n",
    "        df[column] = df[column].fillna('missing')\n",
    "        df[column] = df[column].astype('category')\n",
    "        \n",
    "    return df\n",
    "\n",
    "train  = fill_nan_values(train)\n",
    "test   = fill_nan_values(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "55ecddbb-ad5b-4ce1-a20e-9c93298dce42",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = train.drop(columns=[\"id\", \"price\"])\n",
    "y_train = train[\"price\"]\n",
    "X_test = test.drop(columns=[\"id\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "efb041be-eae3-4fc5-9280-45d1f5723dc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def cross_validate_model_l(model, X_train, y_train, X_test, params, n_splits=5):\n",
    "\n",
    "#     callbacks = [log_evaluation(period=150), early_stopping(stopping_rounds=200)]\n",
    "#     cv = KFold(n_splits=n_splits, shuffle=True, random_state=42)\n",
    "#     val_scores = []\n",
    "#     test_preds = np.zeros((len(X_test), n_splits), dtype=np.float32)\n",
    "\n",
    "#     for fold, (train_ind, valid_ind) in enumerate(cv.split(X_train)):\n",
    "#         # Data splitting\n",
    "#         X_fold_train = X_train.iloc[train_ind]\n",
    "#         y_fold_train = y_train.iloc[train_ind]\n",
    "#         X_val = X_train.iloc[valid_ind]\n",
    "#         y_val = y_train.iloc[valid_ind]\n",
    "        \n",
    "#         clf = model(**params)\n",
    "#         clf.fit(X_fold_train, y_fold_train, eval_set=[(X_val, y_val)], callbacks=callbacks)\n",
    "        \n",
    "#         test_preds[:, fold] = clf.predict(X_test)\n",
    "\n",
    "#         print(\"-\" * 50)\n",
    "#         print(f\"Fold {fold + 1} predictions: {test_preds[:, fold]}\")\n",
    "\n",
    "#     test_preds = np.mean(test_preds, axis=1)\n",
    "#     return clf, test_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a02c34a1-4c72-497c-aa1c-fa66b8a15466",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 34992 candidates, totalling 174960 fits\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from lightgbm import LGBMRegressor\n",
    "from sklearn.metrics import make_scorer, mean_squared_error\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "# 하이퍼파라미터 탐색 범위 설정\n",
    "param_grid = {\n",
    "    'num_leaves': [20, 50, 100, 200],\n",
    "    'max_depth': [5, 10, 15, 20],\n",
    "    'learning_rate': [0.01, 0.05, 0.1],\n",
    "    'n_estimators': [1000, 5000, 10000],\n",
    "    'subsample': [0.5, 0.7, 0.9],\n",
    "    'colsample_bytree': [0.5, 0.7, 0.9],\n",
    "    'reg_alpha': [0.0, 0.1, 1.0],\n",
    "    'reg_lambda': [0.0, 0.1, 1.0],\n",
    "    'min_data_in_leaf': [20, 50, 100]\n",
    "}\n",
    "\n",
    "# LightGBM 모델 초기화\n",
    "lgb_model = LGBMRegressor(random_state=42)\n",
    "\n",
    "# RMSE를 음수로 반환하는 사용자 정의 스코어 함수\n",
    "rmse_scorer = make_scorer(mean_squared_error, greater_is_better=False, squared=False)\n",
    "\n",
    "# K-Fold 교차 검증 설정 (5개의 폴드로 나눔)\n",
    "kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "# GridSearchCV 초기화\n",
    "grid_search = GridSearchCV(\n",
    "    lgb_model,\n",
    "    param_grid=param_grid,\n",
    "    scoring=rmse_scorer,\n",
    "    cv=kf,  # K-Fold 교차 검증 설정\n",
    "    verbose=2,\n",
    "    n_jobs=-1  # 병렬 처리\n",
    ")\n",
    "\n",
    "# 훈련 데이터에 대해 GridSearchCV 수행\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# 최적의 하이퍼파라미터 출력\n",
    "print(\"Best Hyperparameters found by GridSearchCV:\")\n",
    "print(grid_search.best_params_)\n",
    "\n",
    "# 최적의 모델로 예측\n",
    "y_test_pred = grid_search.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df23e836-be7b-4272-b8ff-9d88aad97399",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 튜닝된 하이퍼파라미터 가져오기\n",
    "best_params = grid_search.best_params_  # RandomizedSearchCV를 통해 얻은 최적 하이퍼파라미터\n",
    "# 또는\n",
    "# best_params = grid_search.best_params_  # GridSearchCV를 통해 얻은 최적 하이퍼파라미터\n",
    "\n",
    "# 최적의 하이퍼파라미터로 LightGBM 모델 생성\n",
    "final_model = LGBMRegressor(**best_params)\n",
    "\n",
    "# 전체 훈련 데이터를 사용하여 모델 학습\n",
    "final_model.fit(X_train, y_train)\n",
    "\n",
    "# 테스트 데이터에 대해 예측 수행\n",
    "y_test_pred = final_model.predict(X_test)\n",
    "\n",
    "# 예측 결과 확인 (처음 10개의 예측값 출력)\n",
    "print(\"Test Predictions: \", y_test_pred[:10])\n",
    "\n",
    "# 성능 평가 (RMSE)\n",
    "from sklearn.metrics import mean_squared_error\n",
    "rmse = np.sqrt(mean_squared_error(y_test, y_test_pred))\n",
    "print(f\"Test RMSE: {rmse:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "b11d1e5d-f7dd-4f59-a34a-bc8fe41c4baa",
   "metadata": {},
   "outputs": [],
   "source": [
    "lgb_result =  pd.read_csv('/home/baebro/kaggle_ws/kaggle_competitions/Regression of Used Car Prices/data/sample_submission.csv')\n",
    "lgb_result['price'] = y_test_pred.astype(np.float32)\n",
    "#xgb_result.to_csv('result_xgb.csv', index=False)\n",
    "lgb_result\n",
    "lgb_result.to_csv('submission_lgb_w_original_Optuna_tunning4.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1425af7f-2c76-43c7-addc-46624852b608",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

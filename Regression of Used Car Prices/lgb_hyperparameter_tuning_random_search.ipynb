{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3715b429-e0b7-4194-b1bf-4c930481c389",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd \n",
    "import polars as pl\n",
    "import os\n",
    "import optuna\n",
    "import re\n",
    "import warnings\n",
    "from sklearn.model_selection import KFold, train_test_split\n",
    "from sklearn.metrics import accuracy_score, mean_squared_error\n",
    "import lightgbm as lgb\n",
    "from lightgbm import LGBMRegressor\n",
    "from lightgbm import log_evaluation, early_stopping\n",
    "\n",
    "warnings.simplefilter('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2a232ad1-bbda-4374-9fdd-ad3650321a3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('/home/baebro/kaggle_ws/car price/data/train.csv')\n",
    "test = pd.read_csv('/home/baebro/kaggle_ws/car price/data/test.csv')\n",
    "orig = pd.read_csv('/home/baebro/kaggle_ws/car price/data/used_cars.csv')\n",
    "\n",
    "\n",
    "orig[['milage', 'price']] = orig[['milage', 'price']].apply(\n",
    "    lambda col: col.map(lambda x: int(''.join(re.findall(r'\\d+', str(x))))))\n",
    "\n",
    "train = pd.concat([train, orig], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "dda564b8-fa5e-41f2-ad8a-a9765b3743ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fill_nan_values(df):\n",
    "    \n",
    "    freq = 100\n",
    "    \n",
    "    categoricl_colums = ['brand','model','fuel_type','engine','transmission','ext_col','int_col','accident','clean_title']\n",
    "    re_ = ['model','engine','transmission','ext_col','int_col']\n",
    "    \n",
    "    for column in re_:\n",
    "        df.loc[df[column].value_counts(dropna=False)[df[column]].values < freq, column] = \"noise\"\n",
    "        \n",
    "    for column in categoricl_colums:\n",
    "        df[column] = df[column].fillna('missing')\n",
    "        df[column] = df[column].astype('category')\n",
    "        \n",
    "    return df\n",
    "\n",
    "train  = fill_nan_values(train)\n",
    "test   = fill_nan_values(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "55ecddbb-ad5b-4ce1-a20e-9c93298dce42",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = train.drop(columns=[\"id\", \"price\"])\n",
    "y_train = train[\"price\"]\n",
    "X_test = test.drop(columns=[\"id\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a02c34a1-4c72-497c-aa1c-fa66b8a15466",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from lightgbm import LGBMRegressor\n",
    "from sklearn.metrics import make_scorer, mean_squared_error\n",
    "from sklearn.model_selection import KFold\n",
    "from scipy.stats import randint, uniform\n",
    "\n",
    "from scipy.stats import uniform\n",
    "\n",
    "# 하이퍼파라미터 탐색 범위 설정\n",
    "param_dist = {\n",
    "    'num_leaves': randint(20, 500),\n",
    "    'max_depth': randint(3, 25),\n",
    "    'learning_rate': uniform(0.0001, 0.1),\n",
    "    'n_estimators': randint(100, 10000),\n",
    "    'subsample': uniform(0.5, 1.0),\n",
    "    'colsample_bytree': uniform(0.5, 1.0),\n",
    "    'reg_alpha': uniform(1e-8, 10.0),\n",
    "    'reg_lambda': uniform(1e-8, 10.0),\n",
    "    'min_data_in_leaf': randint(10, 200),\n",
    "    'bagging_fraction':  uniform(0.5, 0.5),\n",
    "    # 수정된 부분: feature_fraction을 0.0과 1.0 사이로 제한\n",
    "    'feature_fraction': uniform(0.5, 0.5)  # 범위를 0.5 ~ 1.0으로 설정 (1.0 초과 불가)\n",
    "}\n",
    "\n",
    "# LightGBM 모델 초기화\n",
    "lgb_model = LGBMRegressor(random_state=42)\n",
    "\n",
    "# RMSE를 음수로 반환하는 사용자 정의 스코어 함수\n",
    "rmse_scorer = make_scorer(mean_squared_error, greater_is_better=False, squared=False)\n",
    "\n",
    "# K-Fold 교차 검증 설정 (5개의 폴드로 나눔)\n",
    "kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "# RandomizedSearchCV 초기화\n",
    "random_search = RandomizedSearchCV(\n",
    "    lgb_model,\n",
    "    param_distributions=param_dist,\n",
    "    n_iter=10,  # 시도할 하이퍼파라미터 조합의 수\n",
    "    scoring=rmse_scorer,\n",
    "    cv=kf,  # K-Fold 교차 검증 설정\n",
    "    verbose=2,\n",
    "    n_jobs=-1,  # 병렬 처리\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "# 훈련 데이터에 대해 RandomizedSearchCV 수행\n",
    "random_search.fit(X_train, y_train)\n",
    "\n",
    "# 최적의 하이퍼파라미터 출력\n",
    "print(\"Best Hyperparameters found by RandomizedSearchCV:\")\n",
    "print(random_search.best_params_)\n",
    "\n",
    "# 최적의 모델로 예측\n",
    "y_test_pred = random_search.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb386174-79ac-4730-bd84-cec9cdbcaba2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 튜닝된 하이퍼파라미터 가져오기\n",
    "best_params = random_search.best_params_  # RandomizedSearchCV를 통해 얻은 최적 하이퍼파라미터\n",
    "# 또는\n",
    "# best_params = grid_search.best_params_  # GridSearchCV를 통해 얻은 최적 하이퍼파라미터\n",
    "\n",
    "# 최적의 하이퍼파라미터로 LightGBM 모델 생성\n",
    "final_model = LGBMRegressor(**best_params)\n",
    "\n",
    "# 전체 훈련 데이터를 사용하여 모델 학습\n",
    "final_model.fit(X_train, y_train)\n",
    "\n",
    "# 테스트 데이터에 대해 예측 수행\n",
    "y_test_pred = final_model.predict(X_test)\n",
    "\n",
    "# 예측 결과 확인 (처음 10개의 예측값 출력)\n",
    "print(\"Test Predictions: \", y_test_pred[:10])\n",
    "\n",
    "# 성능 평가 (RMSE)\n",
    "from sklearn.metrics import mean_squared_error\n",
    "rmse = np.sqrt(mean_squared_error(y_test, y_test_pred))\n",
    "print(f\"Test RMSE: {rmse:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "b11d1e5d-f7dd-4f59-a34a-bc8fe41c4baa",
   "metadata": {},
   "outputs": [],
   "source": [
    "lgb_result =  pd.read_csv('/home/baebro/kaggle_ws/kaggle_competitions/Regression of Used Car Prices/data/sample_submission.csv')\n",
    "lgb_result['price'] = y_test_pred.astype(np.float32)\n",
    "#xgb_result.to_csv('result_xgb.csv', index=False)\n",
    "lgb_result\n",
    "lgb_result.to_csv('submission_lgb_w_original_Optuna_tunning4.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1425af7f-2c76-43c7-addc-46624852b608",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
